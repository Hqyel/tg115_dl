# -*- coding: utf-8 -*-
"""è§£æå™¨æ¨¡å—"""

import time

import requests
from bs4 import BeautifulSoup

from src.channels.config import HEADERS, REQUEST_DELAY, is_valid_115_url
from src.models.resource import Resource
from src.core.database import Database


class TelegraphParser:
  """Telegraph é¡µé¢è§£æå™¨ï¼ˆç”¨äº Lsp115 é¢‘é“ï¼‰"""

  def __init__(self):
    self.session = requests.Session()
    self.session.headers.update(HEADERS)

  def parse_pan_link(self, telegraph_url: str) -> tuple[str, str]:
    """ä» telegraph é¡µé¢è§£æ 115 é“¾æ¥"""
    try:
      response = self.session.get(telegraph_url, timeout=30)
      response.raise_for_status()
    except requests.RequestException as e:
      print(f"è¯·æ±‚å¤±è´¥: {e}")
      return "", ""

    soup = BeautifulSoup(response.text, "lxml")

    pan_url = ""
    for link in soup.find_all("a", href=True):
      href = link.get("href", "")
      link_text = link.get_text(strip=True)
      if is_valid_115_url(href):
        pan_url = href
        break
      if ("æŸ¥çœ‹é“¾æ¥" in link_text or "ğŸ”—" in link_text) and is_valid_115_url(href):
        pan_url = href
        break

    description = ""
    article = soup.find("article")
    if article:
      text = article.get_text(separator="\n", strip=True)
      lines = [l for l in text.split("\n") if l.strip()][:5]
      description = "\n".join(lines)

    if not is_valid_115_url(pan_url):
      return "", description

    return pan_url, description

  def parse_batch(self, db: Database, channel_id: str, limit: int = 100) -> int:
    """æ‰¹é‡è§£ææœªè§£æçš„èµ„æº"""
    resources = db.get_unparsed(channel_id, limit)

    if not resources:
      print("æ²¡æœ‰éœ€è¦è§£æçš„èµ„æº")
      return 0

    print(f"å¼€å§‹è§£æç½‘ç›˜é“¾æ¥ï¼Œå…± {len(resources)} æ¡...")
    print("-" * 50)

    parsed_count = 0
    for i, r in enumerate(resources, 1):
      print(f"[{i}/{len(resources)}] {r.title[:30]}...")

      pan_url, description = self.parse_pan_link(r.telegraph_url)
      r.description = description

      if pan_url:
        r.pan_url = pan_url
        print(f"  âœ“ {pan_url[:50]}...")
        parsed_count += 1
      else:
        # æ ‡è®°ä¸ºå·²å¤„ç†ä½†æ— æœ‰æ•ˆé“¾æ¥ï¼Œé¿å…é‡å¤è§£æ
        r.pan_url = "N/A"
        print(f"  âœ— æœªæ‰¾åˆ°115é“¾æ¥ï¼ˆå·²æ ‡è®°ï¼‰")

      db.save_resource(channel_id, r)
      time.sleep(REQUEST_DELAY)

    print("-" * 50)
    print(f"è§£æå®Œæˆï¼ŒæˆåŠŸ {parsed_count} æ¡")
    return parsed_count
